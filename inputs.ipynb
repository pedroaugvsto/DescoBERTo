{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports necessários"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IGNORAR\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\pedro\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\pedro\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Libraries\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import spacy\n",
    "from transformers import BertTokenizerFast, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "import torch\n",
    "\n",
    "# Pacotes\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nlp = spacy.load('pt_core_news_sm')\n",
    "stop_words = set(stopwords.words('portuguese'))\n",
    "\n",
    "# Tokenizador e modelo do BERT\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
    "model = BertForSequenceClassification.from_pretrained('./best_models/top1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definição das funções"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparo do Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpeza do texto\n",
    "def text_cleaning(text):\n",
    "    text = re.sub(r'@\\w+|USER', '', text) # Usernames\n",
    "    text = re.sub(r'http\\S+', '', text) # Links\n",
    "    text = re.sub(r'\\brt\\b|\\bRT\\b', '', text) # RTs\n",
    "    text = re.sub(r'#\\w+', '', text) # Hashtags\n",
    "    text = re.sub(r'\\n', '', text) # Quebras de linha\n",
    "    text = re.sub(r'\\w*\\d\\w*', '', text) # Palavraas com dígitos\n",
    "    text = re.sub(r'\\b\\w{1,2}\\b', '', text) # Palavras com 1 ou 2 caracteres\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text) # Pontuações e caracteres especiais\n",
    "    text = re.sub(r'\\s+', ' ', text) # Espaços extras\n",
    "    text = text.lower() # Normalização\n",
    "    text = ' '.join(word for word in text.split() if word not in stop_words) # Stop Words\n",
    "    return text\n",
    "\n",
    "# Tokenização\n",
    "def text_tokenizing(text):\n",
    "    text = word_tokenize(text) # Tokenização\n",
    "    text = [token.lemma_ for token in nlp(' '.join(text))] # Lematização\n",
    "    text = ' '.join(text) # Junção em uma string\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processamento da entrada e definição do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processamento da entrada\n",
    "def process_text(text):\n",
    "    text = text_cleaning(text) # Limpeza\n",
    "    text = text_tokenizing(text) # Tokenização\n",
    "    inputs = tokenizer(text, truncation=True, padding=True, max_length=128, return_tensors=\"pt\") # Tokenização do BERT\n",
    "    input_ids = torch.tensor(inputs['input_ids'])\n",
    "    attention_mask = torch.tensor(inputs['attention_mask'])\n",
    "    return input_ids, attention_mask\n",
    "\n",
    "def create_table(probabilities):\n",
    "    categories = ['homophobia', 'obscene', 'insult', 'racism', 'sexism', 'xenophobia']\n",
    "    table = pd.DataFrame({'Confidence': probabilities}, index=categories)\n",
    "    return table\n",
    "\n",
    "def run_model(text):\n",
    "    input_ids, attention_mask = process_text(text)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)   \n",
    "    predictions = outputs.logits\n",
    "    probabilities = torch.sigmoid(predictions)\n",
    "    table = create_table(probabilities[0].tolist())\n",
    "    return table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tweets de teste\n",
    "test_0 = 'Bom dia, meu nome é Pedro, estou testando aqui, espero que dê certo.'\n",
    "test_h = 'Vai se fuder, seu viado'\n",
    "test_o = 'Chupa meu penis'\n",
    "test_i = 'Você é feio e burro'\n",
    "test_r = 'Negro é tudo macaco'\n",
    "test_s = 'Lugar de mulher é na cozinha'\n",
    "test_x = 'Nordestinos estúpidos, odeio esses paraíbas'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bom dia, meu nome é Pedro, estou testando aqui, espero que dê certo. \n",
      " \n",
      "             Confidence\n",
      "homophobia    0.003743\n",
      "obscene       0.021096\n",
      "insult        0.043341\n",
      "racism        0.013287\n",
      "sexism        0.005411\n",
      "xenophobia    0.016780\n"
     ]
    }
   ],
   "source": [
    "# Caso de teste não ofensivo\n",
    "print(test_0, '\\n', '\\n', run_model(test_0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vai se fuder, seu viado \n",
      " \n",
      "             Confidence\n",
      "homophobia    0.847613\n",
      "obscene       0.096368\n",
      "insult        0.035589\n",
      "racism        0.026905\n",
      "sexism        0.066892\n",
      "xenophobia    0.024918\n"
     ]
    }
   ],
   "source": [
    "# Caso de teste homofobia\n",
    "print(test_h, '\\n', '\\n', run_model(test_h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chupa meu penis \n",
      " \n",
      "             Confidence\n",
      "homophobia    0.008064\n",
      "obscene       0.795792\n",
      "insult        0.242764\n",
      "racism        0.005088\n",
      "sexism        0.037759\n",
      "xenophobia    0.005256\n"
     ]
    }
   ],
   "source": [
    "# Caso de teste obscenidade\n",
    "print(test_o, '\\n', '\\n', run_model(test_o))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Você é feio e burro \n",
      " \n",
      "             Confidence\n",
      "homophobia    0.003949\n",
      "obscene       0.054130\n",
      "insult        0.871376\n",
      "racism        0.010363\n",
      "sexism        0.008329\n",
      "xenophobia    0.023967\n"
     ]
    }
   ],
   "source": [
    "# Caso de teste insulto\n",
    "print(test_i, '\\n', '\\n', run_model(test_i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negro é tudo macaco \n",
      " \n",
      "             Confidence\n",
      "homophobia    0.052102\n",
      "obscene       0.045388\n",
      "insult        0.031790\n",
      "racism        0.588748\n",
      "sexism        0.034853\n",
      "xenophobia    0.160486\n"
     ]
    }
   ],
   "source": [
    "# Caso de teste racismo\n",
    "print(test_r, '\\n', '\\n', run_model(test_r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lugar de mulher é na cozinha \n",
      " \n",
      "             Confidence\n",
      "homophobia    0.123143\n",
      "obscene       0.094863\n",
      "insult        0.048060\n",
      "racism        0.018034\n",
      "sexism        0.430947\n",
      "xenophobia    0.020139\n"
     ]
    }
   ],
   "source": [
    "# Caso de teste sexismo\n",
    "print(test_s, '\\n', '\\n', run_model(test_s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nordestinos estúpidos, odeio esses paraíbas \n",
      " \n",
      "             Confidence\n",
      "homophobia    0.060140\n",
      "obscene       0.072788\n",
      "insult        0.054870\n",
      "racism        0.206460\n",
      "sexism        0.075218\n",
      "xenophobia    0.646207\n"
     ]
    }
   ],
   "source": [
    "# Caso de teste xenofobia\n",
    "print(test_x, '\\n', '\\n', run_model(test_x))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
