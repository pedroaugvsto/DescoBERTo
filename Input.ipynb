{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports necessários"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IGNORAR\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\pedro\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\pedro\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Libraries\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import spacy\n",
    "from transformers import BertTokenizerFast, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "import torch\n",
    "from torch.utils.data import Dataset, TensorDataset\n",
    "\n",
    "# Pacotes\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nlp = spacy.load('pt_core_news_sm')\n",
    "stop_words = set(stopwords.words('portuguese'))\n",
    "\n",
    "# Tokenizador e modelo do BERT\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
    "model = BertForSequenceClassification.from_pretrained('./best-model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definição das funções"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparo do Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpeza do texto\n",
    "def text_cleaning(text):\n",
    "    text = re.sub(r'@\\w+|USER', '', text) # Usernames\n",
    "    text = re.sub(r'http\\S+', '', text) # Links\n",
    "    text = re.sub(r'\\brt\\b|\\bRT\\b', '', text) # RTs\n",
    "    text = re.sub(r'#\\w+', '', text) # Hashtags\n",
    "    text = re.sub(r'\\n', '', text) # Quebras de linha\n",
    "    text = re.sub(r'\\w*\\d\\w*', '', text) # Palavraas com dígitos\n",
    "    text = re.sub(r'\\b\\w{1,2}\\b', '', text) # Palavras com 1 ou 2 caracteres\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text) # Pontuações e caracteres especiais\n",
    "    text = re.sub(r'\\s+', ' ', text) # Espaços extras\n",
    "    text = text.lower() # Normalização\n",
    "    text = ' '.join(word for word in text.split() if word not in stop_words) # Stop Words\n",
    "    return text\n",
    "\n",
    "# Tokenização\n",
    "def text_tokenizing(text):\n",
    "    text = word_tokenize(text) # Tokenização\n",
    "    text = [token.lemma_ for token in nlp(' '.join(text))] # Lematização\n",
    "    text = ' '.join(text) # Junção em uma string\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processamento da entrada e definição do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processamento da entrada\n",
    "def process_text(text):\n",
    "    text = text_cleaning(text) # Limpeza\n",
    "    text = text_tokenizing(text) # Tokenização\n",
    "    inputs = tokenizer(text, truncation=True, padding=True, max_length=128, return_tensors=\"pt\") # Tokenização do BERT\n",
    "    input_ids = torch.tensor(inputs['input_ids'])\n",
    "    attention_mask = torch.tensor(inputs['attention_mask'])\n",
    "    return input_ids, attention_mask\n",
    "\n",
    "def create_table(probabilities):\n",
    "    categories = ['homophobia', 'obscene', 'insult', 'racism', 'sexism', 'xenophobia']\n",
    "    table = pd.DataFrame({'Confidence': probabilities}, index=categories)\n",
    "    return table\n",
    "\n",
    "def run_model(text):\n",
    "    input_ids, attention_mask = process_text(text)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)   \n",
    "    predictions = outputs.logits\n",
    "    probabilities = torch.sigmoid(predictions)\n",
    "    table = create_table(probabilities[0].tolist())\n",
    "    return table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 'Bom dia, meu nome é Pedro, estou testando aqui, espero que dê certo.'\n",
    "y = 'vai se fuder seu viado'\n",
    "z = 'lugar de mulher é na cozinha'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Confidence\n",
      "homophobia    0.003036\n",
      "obscene       0.032702\n",
      "insult        0.029382\n",
      "racism        0.004499\n",
      "sexism        0.006886\n",
      "xenophobia    0.005788 \n",
      "\n",
      "            Confidence\n",
      "homophobia    0.810573\n",
      "obscene       0.710732\n",
      "insult        0.726098\n",
      "racism        0.067573\n",
      "sexism        0.114067\n",
      "xenophobia    0.037959 \n",
      "\n",
      "            Confidence\n",
      "homophobia    0.043930\n",
      "obscene       0.191062\n",
      "insult        0.598940\n",
      "racism        0.040935\n",
      "sexism        0.589884\n",
      "xenophobia    0.038734\n"
     ]
    }
   ],
   "source": [
    "# Casos de teste \n",
    "print(run_model(x), '\\n')\n",
    "print(run_model(y), '\\n')\n",
    "print(run_model(z))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
