{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports necessários"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IGNORAR\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\pedro\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\pedro\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Libraries\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import spacy\n",
    "from transformers import BertTokenizerFast, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "import torch\n",
    "\n",
    "# Pacotes\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nlp = spacy.load('pt_core_news_sm')\n",
    "stop_words = set(stopwords.words('portuguese'))\n",
    "\n",
    "# Tokenizador e modelo do BERT\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
    "model = BertForSequenceClassification.from_pretrained('./best_models/top3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definição das funções"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparo do Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpeza do texto\n",
    "def text_cleaning(text):\n",
    "    text = re.sub(r'@\\w+|USER', '', text) # Usernames\n",
    "    text = re.sub(r'http\\S+', '', text) # Links\n",
    "    text = re.sub(r'\\brt\\b|\\bRT\\b', '', text) # RTs\n",
    "    text = re.sub(r'#\\w+', '', text) # Hashtags\n",
    "    text = re.sub(r'\\n', '', text) # Quebras de linha\n",
    "    text = re.sub(r'\\w*\\d\\w*', '', text) # Palavraas com dígitos\n",
    "    text = re.sub(r'\\b\\w{1,2}\\b', '', text) # Palavras com 1 ou 2 caracteres\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text) # Pontuações e caracteres especiais\n",
    "    text = re.sub(r'\\s+', ' ', text) # Espaços extras\n",
    "    text = text.lower() # Normalização\n",
    "    text = ' '.join(word for word in text.split() if word not in stop_words) # Stop Words\n",
    "    return text\n",
    "\n",
    "# Tokenização\n",
    "def text_tokenizing(text):\n",
    "    text = word_tokenize(text) # Tokenização\n",
    "    text = [token.lemma_ for token in nlp(' '.join(text))] # Lematização\n",
    "    text = ' '.join(text) # Junção em uma string\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processamento da entrada e definição do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processamento da entrada\n",
    "def process_text(text):\n",
    "    text = text_cleaning(text) # Limpeza\n",
    "    text = text_tokenizing(text) # Tokenização\n",
    "    inputs = tokenizer(text, truncation=True, padding=True, max_length=128, return_tensors=\"pt\") # Tokenização do BERT\n",
    "    input_ids = torch.tensor(inputs['input_ids'])\n",
    "    attention_mask = torch.tensor(inputs['attention_mask'])\n",
    "    return input_ids, attention_mask\n",
    "\n",
    "def create_table(probabilities):\n",
    "    categories = ['homophobia', 'obscene', 'insult', 'racism', 'sexism', 'xenophobia']\n",
    "    table = pd.DataFrame({'Confidence': probabilities}, index=categories)\n",
    "    return table\n",
    "\n",
    "def run_model(text):\n",
    "    input_ids, attention_mask = process_text(text)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)   \n",
    "    predictions = outputs.logits\n",
    "    probabilities = torch.sigmoid(predictions)\n",
    "    table = create_table(probabilities[0].tolist())\n",
    "    return table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tweets de teste\n",
    "test_0 = 'Bom dia, meu nome é Pedro, estou testando aqui, espero que dê certo.'\n",
    "test_h = 'Vai se fuder, seu viado'\n",
    "test_o = 'Chupa meu penis'\n",
    "test_i = 'Você é feio e burro'\n",
    "test_r = 'Negro é tudo macaco'\n",
    "test_s = 'Lugar de mulher é na cozinha'\n",
    "test_x = 'Nordestinos estúpidos, odeio esses paraíbas'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bom dia, meu nome é Pedro, estou testando aqui, espero que dê certo. \n",
      " \n",
      "             Confidence\n",
      "homophobia    0.003036\n",
      "obscene       0.032702\n",
      "insult        0.029382\n",
      "racism        0.004499\n",
      "sexism        0.006886\n",
      "xenophobia    0.005788\n"
     ]
    }
   ],
   "source": [
    "# Caso de teste não ofensivo\n",
    "print(test_0, '\\n', '\\n', run_model(test_0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vai se fuder, seu viado \n",
      " \n",
      "             Confidence\n",
      "homophobia    0.810573\n",
      "obscene       0.710732\n",
      "insult        0.726098\n",
      "racism        0.067573\n",
      "sexism        0.114067\n",
      "xenophobia    0.037959\n"
     ]
    }
   ],
   "source": [
    "# Caso de teste homofobia\n",
    "print(test_h, '\\n', '\\n', run_model(test_h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chupa meu penis \n",
      " \n",
      "             Confidence\n",
      "homophobia    0.035690\n",
      "obscene       0.943469\n",
      "insult        0.226441\n",
      "racism        0.027718\n",
      "sexism        0.210055\n",
      "xenophobia    0.011054\n"
     ]
    }
   ],
   "source": [
    "# Caso de teste obscenidade\n",
    "print(test_o, '\\n', '\\n', run_model(test_o))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Você é feio e burro \n",
      " \n",
      "             Confidence\n",
      "homophobia    0.008164\n",
      "obscene       0.034265\n",
      "insult        0.878321\n",
      "racism        0.012569\n",
      "sexism        0.013404\n",
      "xenophobia    0.042368\n"
     ]
    }
   ],
   "source": [
    "# Caso de teste insulto\n",
    "print(test_i, '\\n', '\\n', run_model(test_i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negro é tudo macaco \n",
      " \n",
      "             Confidence\n",
      "homophobia    0.159203\n",
      "obscene       0.041068\n",
      "insult        0.569003\n",
      "racism        0.060268\n",
      "sexism        0.051079\n",
      "xenophobia    0.142132\n"
     ]
    }
   ],
   "source": [
    "# Caso de teste racismo\n",
    "print(test_r, '\\n', '\\n', run_model(test_r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lugar de mulher é na cozinha \n",
      " \n",
      "             Confidence\n",
      "homophobia    0.043930\n",
      "obscene       0.191062\n",
      "insult        0.598940\n",
      "racism        0.040935\n",
      "sexism        0.589884\n",
      "xenophobia    0.038734\n"
     ]
    }
   ],
   "source": [
    "# Caso de teste sexismo\n",
    "print(test_s, '\\n', '\\n', run_model(test_s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nordestinos estúpidos, odeio esses paraíbas \n",
      " \n",
      "             Confidence\n",
      "homophobia    0.008521\n",
      "obscene       0.035702\n",
      "insult        0.411464\n",
      "racism        0.018352\n",
      "sexism        0.041906\n",
      "xenophobia    0.068300\n"
     ]
    }
   ],
   "source": [
    "# Caso de teste xenofobia\n",
    "print(test_x, '\\n', '\\n', run_model(test_x))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
